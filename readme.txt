# Memory-Based AI Chatbot

A Streamlit-based chatbot with memory architecture featuring persona, short-term and long-term memory using FAISS vector search.

## ğŸ—ï¸ Project Structure

```
New folder/
â”œâ”€â”€ app.py                      # Main Streamlit application
â”œâ”€â”€ .env                        # Environment variables (API keys)
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ test_imports.py            # Test script to verify setup
â”œâ”€â”€ vectorstore.py             # FAISS vector store implementation
â”œâ”€â”€ config/
â”‚   â””â”€â”€ constants.py           # Configuration constants
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ api_client.py          # OpenRouter API client (commented out)
â”‚   â”œâ”€â”€ context_assembler.py   # Prompt building with memory retrieval
â”‚   â””â”€â”€ fact_extractor.py      # Fact extraction and storage
â”œâ”€â”€ data/                      # Data storage directory
â”‚   â”œâ”€â”€ facts.json            # Stored facts
â”‚   â”œâ”€â”€ memory.jsonl          # Short-term conversation memory
â”‚   â””â”€â”€ long_term_memory.jsonl # Long-term session summaries
â”œâ”€â”€ memory/
â”‚   â”œâ”€â”€ session_summarizer.py  # Session summarization
â”‚   â”œâ”€â”€ long_term_memory.py    # Long-term memory management
â”‚   â”œâ”€â”€ context_retriever.py   # FAISS-based memory retrieval
â”‚   â”œâ”€â”€ fact_memory.py         # Fact memory utilities
â”‚   â””â”€â”€ turn_memory.py         # Turn-by-turn memory storage
â”œâ”€â”€ persona/
â”‚   â”œâ”€â”€ mood_adjustments.json  # Current mood settings
â”‚   â”œâ”€â”€ relationship_status.py # User relationship tracking
â”‚   â”œâ”€â”€ mood_tracker.py        # Mood tracking utilities
â”‚   â”œâ”€â”€ persona.json           # AI persona definition
â”‚   â””â”€â”€ personality.json       # Personality traits
â””â”€â”€ utils/
    â”œâ”€â”€ session_id.py          # Session management
    â””â”€â”€ ui_helpers.py          # Streamlit UI utilities
```

## ğŸš€ Quick Start

1. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

2. **Set up environment:**
   - Copy `.env` and add your OpenRouter API key:
   ```
   OPENROUTER_API_KEY=your_api_key_here
   ```

3. **Test the setup:**
   ```bash
   python test_imports.py
   ```

4. **Run the application:**
   ```bash
   streamlit run app.py
   ```

## ğŸ§  How It Works

### Memory Architecture
- **Short-term Memory**: Stores recent conversation turns in `memory.jsonl`
- **Long-term Memory**: Session summaries stored in `long_term_memory.jsonl`
- **FAISS Vector Search**: Retrieves relevant memories based on semantic similarity
- **Fact Storage**: Extracts and stores user facts in `facts.json`

### Persona System
- **Persona**: AI identity, goals, and pronouns
- **Personality**: Tone, style, temperament, formality
- **Mood**: Current emotional state with intensity tracking

### Prompt Assembly
1. Loads persona and personality traits
2. Retrieves relevant short-term memories via FAISS
3. Retrieves relevant long-term summaries
4. Combines everything into a contextual prompt

## ğŸ”§ Current Status

- âœ… Memory storage and retrieval system
- âœ… FAISS vector search implementation  
- âœ… Persona and mood system
- âœ… Fact extraction and storage
- âœ… Session management
- ğŸš§ LLM integration (scaffolding in place, commented out)

## ğŸ¯ Usage

1. Start chatting - your messages are stored and facts are extracted
2. The system builds contextual prompts using:
   - Your persona (Isabella)
   - Relevant conversation history
   - Your current mood and personality
3. Use "End Chat & Save to Long-Term Memory" to summarize sessions
4. View debug info in the sidebar

## ğŸ”„ Next Steps

1. Uncomment LLM integration in `app.py` and `session_summarizer.py`
2. Add your OpenRouter API key to enable actual AI responses
3. Customize persona/personality files to match your preferences

## ğŸ› Troubleshooting

- If imports fail, run `python test_imports.py` to diagnose
- Check that all `__init__.py` files are present
- Ensure the `data/` directory exists and is writable
- Verify your `.env` file is properly configured

## ğŸ“ Notes

- Currently shows generated prompts instead of LLM responses
- FAISS embeddings use BGE-M3 model (downloaded on first run)
- All memory is stored locally in JSON/JSONL files
- Session IDs are generated per browser session
